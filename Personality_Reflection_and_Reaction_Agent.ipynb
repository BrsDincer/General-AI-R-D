{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "hlBD9NZJH7lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External"
      ],
      "metadata": {
        "id": "nJcq7IF3w6Cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbWHUw1KHkXF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install 'pyautogen[gemini]~=0.2.0b4'\n",
        "!pip install 'langchain_experimental==0.0.49'\n",
        "!pip install 'langchain-openai==0.0.3'\n",
        "!pip install 'faiss-cpu==1.7.4'\n",
        "!pip install 'huggingface_hub==0.20.2'\n",
        "!pip install 'wikipedia==1.4.0'\n",
        "!pip install 'google-generativeai==0.3.2'\n",
        "!pip install 'chromadb==0.4.22'\n",
        "!pip install 'pypdf==3.17.4'\n",
        "!pip install 'weasyprint==60.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base"
      ],
      "metadata": {
        "id": "iIFxJKE-w8SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime,timedelta\n",
        "from typing import Union,Optional,List,Dict,Any,Type\n",
        "from termcolor import colored\n",
        "import math,faiss,os,shutil"
      ],
      "metadata": {
        "id": "I9mivcp5w9vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia as wpp"
      ],
      "metadata": {
        "id": "4TBZrRQb84RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weasyprint"
      ],
      "metadata": {
        "id": "E1lf9khtdppI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "ai_p6lrc0R1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "from autogen.code_utils import content_str"
      ],
      "metadata": {
        "id": "yUzKjqRQHiFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions"
      ],
      "metadata": {
        "id": "MhYuGhH8IcFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import google.ai.generativelanguage as glm"
      ],
      "metadata": {
        "id": "M55AfKtH_sZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "0GUj7CxkxDcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "Vc8R1HhrxLs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI,OpenAI,OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "bYw23onYxRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.generative_agents import GenerativeAgent,GenerativeAgentMemory"
      ],
      "metadata": {
        "id": "Ro1xb6RqH-Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "XNh9Inl2zeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "GOtqvrr2hiIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilization"
      ],
      "metadata": {
        "id": "h2qnavzByEoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class"
      ],
      "metadata": {
        "id": "x3UqLMHwyL6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassInitial:\n",
        "  pass\n",
        "class ResultInitial:\n",
        "  pass\n",
        "class ModelInitial:\n",
        "  pass\n",
        "class ProcessInitial:\n",
        "  pass\n",
        "class URLInitial:\n",
        "  pass\n",
        "class ElementInitial:\n",
        "  pass\n",
        "class DocumentationInitial:\n",
        "  pass\n",
        "class ErrorInitial:\n",
        "  pass\n",
        "class NullInitial:\n",
        "  pass"
      ],
      "metadata": {
        "id": "f9G_EaErKBSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Functions"
      ],
      "metadata": {
        "id": "CEFkXSzuyhE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CreateDirectory:ProcessInitial = lambda x: os.mkdir(x) if not os.path.exists(x) else None\n",
        "DeleteDirectory:ProcessInitial = lambda x: shutil.rmtree(x) if len(os.listdir(z)) > 1 else None\n",
        "SortDirectoryFile:ProcessInitial = lambda x: [\"/content/modelFiles/\"+str(y) for y in os.listdir(str(x)) if y != \".ipynb_checkpoints\"]"
      ],
      "metadata": {
        "id": "_6TwmZ4wybGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ErrorModule(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.error:ErrorInitial = NotImplementedError(NotImplemented)\n",
        "  def __str__(self)->str:\n",
        "    return \"Error Modulation\"\n",
        "  def __call__(self)->ErrorInitial:\n",
        "    return self.error\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    raise self.error\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return ErrorModule.__doc__\n",
        "  @property\n",
        "  def Default(self)->ErrorInitial:\n",
        "    raise self.error\n",
        "  def Manuel(self,errorType:ErrorInitial,errorMessage:str)->ErrorInitial:\n",
        "    raise errorType(errorMessage)"
      ],
      "metadata": {
        "id": "mWvDCkVxywmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DefineCredentials(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.openAIKey = userdata.get(\"OPENAI_API_KEY\")\n",
        "    self.huggingKey = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "    self.googleKey = userdata.get(\"GOOGLE_API_ADDITIONAL\")\n",
        "    self.geminiKey = userdata.get(\"GEMINI_API_ADDITIONAL\")\n",
        "    self.cseIDKey = userdata.get(\"CSE_ID_KEY\")\n",
        "  def __str__(self)->str:\n",
        "    return \"Credential Return Modulation\"\n",
        "  def __call__(self)->NullInitial:\n",
        "    return None\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    ErrorModule().Default\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return DefineCredentials.__doc__\n",
        "  def OpenAISave(self)->ProcessInitial:\n",
        "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "      os.environ[\"OPENAI_API_KEY\"] = self.openAIKey\n",
        "      openai.api_key = self.openAIKey\n",
        "      globals()[\"OPENAI_KEY\"] = self.openAIKey\n",
        "    else:\n",
        "      openai.api_key = self.openAIKey\n",
        "      globals()[\"OPENAI_KEY\"] = self.openAIKey\n",
        "  def GeminiSave(self)->ProcessInitial:\n",
        "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
        "      os.environ[\"GEMINI_API_KEY\"] = self.geminiKey\n",
        "      globals()[\"GEMINI_KEY\"] = self.geminiKey\n",
        "    else:\n",
        "      globals()[\"GEMINI_KEY\"] = self.geminiKey\n",
        "  def HuggingSave(self)->ProcessInitial:\n",
        "    if not os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
        "      os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = self.huggingKey\n",
        "      globals()[\"HUGGING_KEY\"] = self.huggingKey\n",
        "      !huggingface-cli login --token $HUGGING_KEY\n",
        "    else:\n",
        "      globals()[\"HUGGING_KEY\"] = self.huggingKey\n",
        "      !huggingface-cli login --token $HUGGING_KEY\n",
        "  def GoogleSave(self)->ProcessInitial:\n",
        "    if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "      os.environ[\"GOOGLE_API_KEY\"] = self.googleKey\n",
        "      globals()[\"GOOGLE_KEY\"] = self.googleKey\n",
        "    else:\n",
        "      globals()[\"GOOGLE_KEY\"] = self.googleKey\n",
        "    if not os.environ.get(\"GOOGLE_CSE_ID\"):\n",
        "      os.environ[\"GOOGLE_CSE_ID\"] = self.cseIDKey\n",
        "      globals()[\"CSE_KEY\"] = self.cseIDKey\n",
        "    else:\n",
        "      globals()[\"CSE_KEY\"] = self.cseIDKey"
      ],
      "metadata": {
        "id": "N2dve1IvzSsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "qdTBJajh2pVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().OpenAISave()"
      ],
      "metadata": {
        "id": "AbQMpd962YxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().GeminiSave()"
      ],
      "metadata": {
        "id": "px_tkQwi20Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "DefineCredentials().HuggingSave()"
      ],
      "metadata": {
        "id": "MqU8cW5y21aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().GoogleSave()"
      ],
      "metadata": {
        "id": "HCGUbcgl22nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autogenConfiguration:list = [\n",
        "    {\n",
        "        \"model\":\"gpt-4-1106-preview\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\":\"gpt-4-vision-preview\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\":\"dalle\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gemini-pro\",\n",
        "        \"api_key\": os.environ.get(\"GEMINI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gemini-pro-vision\",\n",
        "        \"api_key\": os.environ.get(\"GEMINI_API_KEY\")\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "iYHwWlBsaaTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Structure"
      ],
      "metadata": {
        "id": "8FDdrPpd3r5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure"
      ],
      "metadata": {
        "id": "MyDBgfee48mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMStructure(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.mistral = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "    self.modelOpenAI = \"gpt-4\"\n",
        "  def __str__(self)->str:\n",
        "    return \"LLM Modulation\"\n",
        "  def __call__(self)->NullInitial:\n",
        "    return None\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    ErrorModule().Default\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return LLMStructure.__doc__\n",
        "  def Load(self,LLMType:str=\"openai\")->ModelInitial:\n",
        "    if LLMType.lower() == \"hugging\":\n",
        "      llm = HuggingFaceHub(\n",
        "          repo_id = self.mistral,\n",
        "          task=\"text-generation\",\n",
        "          model_kwargs={\n",
        "              \"temperature\":0.4\n",
        "          }\n",
        "      )\n",
        "    elif LLMType.lower() == \"openai\":\n",
        "      llm = ChatOpenAI(\n",
        "          temperature=0.4,\n",
        "          max_tokens=4096,\n",
        "          model_name=self.modelOpenAI,\n",
        "          api_key=userdata.get(\"OPENAI_API_KEY\")\n",
        "      )\n",
        "    else:\n",
        "      ErrorModule().Manuel(ValueError,\"Choose a viable LLM structure\")\n",
        "    return llm"
      ],
      "metadata": {
        "id": "0QfXTjay3Tyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "08yHwfv449xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "openAIModel = LLMStructure().Load()\n",
        "mistralAIModel = LLMStructure().Load(LLMType=\"hugging\")"
      ],
      "metadata": {
        "id": "T95N18FM48FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gathering Data Functions"
      ],
      "metadata": {
        "id": "9JNyTF0J8-UQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wikipedia"
      ],
      "metadata": {
        "id": "5ER71PXj9Aik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WikipediaSearch(targetTopic:Optional[str],searchLimit:Optional[int],**load_kwargs:Any)->list:\n",
        "  results = []\n",
        "  contents = []\n",
        "  response = wpp.search(targetTopic,results=searchLimit)\n",
        "  if (len(response) > 0) and (response is not None):\n",
        "    for index in response:\n",
        "      try:\n",
        "        pageInformationUrl = wpp.page(\n",
        "            str(index),\n",
        "            **load_kwargs\n",
        "        ).url\n",
        "        results.append(pageInformationUrl)\n",
        "        content = wpp.page(\n",
        "            str(index),\n",
        "            **load_kwargs\n",
        "        ).content\n",
        "        contents.append(content)\n",
        "      except:\n",
        "        pass\n",
        "    if len(results) > 0 and len(contents) > 0:\n",
        "      return results,contents\n",
        "    else:\n",
        "      return None,None\n",
        "  else:\n",
        "    ErrorModule().Default"
      ],
      "metadata": {
        "id": "25CfX8tX9CM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating PDF"
      ],
      "metadata": {
        "id": "teiDfpdKdVMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CreatePDFFromURL(urls:URLInitial|list)->ProcessInitial:\n",
        "  CreateDirectory(\"/content/modelFiles\")\n",
        "  for c,url in enumerate(urls):\n",
        "    try:\n",
        "      main = weasyprint.HTML(url).write_pdf()\n",
        "      path = os.path.join(\"modelFiles\",f\"retrieve_pdf_{str(c)}.pdf\")\n",
        "      with open(path,\"wb\") as ops:\n",
        "        ops.write(main)\n",
        "    except:\n",
        "      pass"
      ],
      "metadata": {
        "id": "0VIP5ukodXYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Score & Memory Functions"
      ],
      "metadata": {
        "id": "6GVMYPDl5ReD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Score"
      ],
      "metadata": {
        "id": "OICiEBlA5Ulb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RelevanceScore(score:int or float)->float:\n",
        "  # This function converts the euclidean norm of normalized embeddings\n",
        "  # (0 is most similar, sqrt(2) most dissimilar) to a similarity function (0 to 1)\n",
        "  return 1.0-score/math.sqrt(2)"
      ],
      "metadata": {
        "id": "lbizaxyP5Kx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory Retriever"
      ],
      "metadata": {
        "id": "iA0HHNph5onS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddingOpenAICache = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=userdata.get(\"OPENAI_API_KEY\"),\n",
        "    model_name=\"text-embedding-ada-002\"\n",
        ")"
      ],
      "metadata": {
        "id": "cHuK39bQIlg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MemoryRetriever()->ClassInitial:\n",
        "  embeddingModel = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "  size = 1536\n",
        "  index = faiss.IndexFlatL2(size)\n",
        "  store = FAISS(\n",
        "      embeddingModel.embed_query,\n",
        "      index,\n",
        "      InMemoryDocstore({}),\n",
        "      {},\n",
        "      relevance_score_fn=RelevanceScore\n",
        "  )\n",
        "  vectorStore = TimeWeightedVectorStoreRetriever(\n",
        "      vectorstore=store,\n",
        "      other_score_keys=[\"importance\"],\n",
        "      k=15\n",
        "  )\n",
        "  return vectorStore"
      ],
      "metadata": {
        "id": "2GExxXb75l9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing Method AI"
      ],
      "metadata": {
        "id": "IrSWwjMqZt5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions & Constants"
      ],
      "metadata": {
        "id": "148UjQOreKTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoReply = \"Always give the final answer as text and add 'TERMINATE' at the end\""
      ],
      "metadata": {
        "id": "vAMjs6F5eZvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "systemMessage = \"Using the documents given to you, infer personality traits\""
      ],
      "metadata": {
        "id": "zk9bKU7Qf_9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personalMessage = (\n",
        "    \"Use one-sentence descriptive phrases. \"\n",
        "    \"Make complete sentences in accordance with the language rules. \"\n",
        "    \"For example: 'He/she remembers his/her dog, from when he/she was a kid', 'He/she feels tired from driving so far', 'He/she sees the new home'. \"\n",
        "    \"Return them as a string array.\"\n",
        ")"
      ],
      "metadata": {
        "id": "7C7k8nsU37KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem = \"Using these documents, extract personality traits and return them as a string array\""
      ],
      "metadata": {
        "id": "ddE4Pk3-gByA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddingOpenAICache = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=userdata.get(\"OPENAI_API_KEY\"),\n",
        "    model_name=\"text-embedding-ada-002\"\n",
        ")"
      ],
      "metadata": {
        "id": "mSYvU3mJbcQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitterCallback = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\",\"\\r\",\"\\t\"]\n",
        ")"
      ],
      "metadata": {
        "id": "M6bJ7HCLb9Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RetrieveCallback(assistantInitial:ModelInitial,problem:str=problem,description:str=autoReply)->str:\n",
        "  for v in assistantInitial.chat_messages.values():\n",
        "    if v and len(v) > 0:\n",
        "      for d in v:\n",
        "        if (d[\"content\"] is not None) and (d[\"content\"] != \" \") and (d[\"content\"].lower() != str(problem).lower()) and (d[\"content\"].lower() != str(description).lower()) and (d[\"content\"] != \"\") and (d[\"content\"].upper() != \"UPDATE CONTEXT\"):\n",
        "          try:\n",
        "            content = content_str(d[\"content\"])\n",
        "          except:\n",
        "            content = d[\"content\"]\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      content = \"There is no data for response\"\n",
        "  return content"
      ],
      "metadata": {
        "id": "PgDM3IQkeMJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assistant"
      ],
      "metadata": {
        "id": "xNP5lHt9ahBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReturnAssistantAgent(message:str=systemMessage)->ModelInitial:\n",
        "  assistant = RetrieveAssistantAgent(\n",
        "      name=\"personality_traits_assistant\",\n",
        "      system_message=message,\n",
        "      llm_config={\n",
        "          \"timeout\":600,\n",
        "          \"cache_seed\":42,\n",
        "          \"config_list\":autogenConfiguration,\n",
        "      }\n",
        "  )\n",
        "  return assistant"
      ],
      "metadata": {
        "id": "zOfaIuCR6QoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proxy"
      ],
      "metadata": {
        "id": "U924Kh_Sb8Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReturnProxyAgent(documentList:list,model:str=\"gemini-pro\")->ModelInitial:\n",
        "  CreateDirectory(\"/content/modelFiles\")\n",
        "  pathAll = os.path.join(os.path.abspath(\"\"),\"modelFiles\")\n",
        "  documentList.append(pathAll)\n",
        "  agent = RetrieveUserProxyAgent(\n",
        "      name=\"ragproxyagent\",\n",
        "      human_input_mode=\"NEVER\",\n",
        "      default_auto_reply=autoReply,\n",
        "      max_consecutive_auto_reply=10,\n",
        "      retrieve_config={\n",
        "          \"task\":\"qa\",\n",
        "          \"docs_path\":documentList,\n",
        "          \"chunk_token_size\":2000,\n",
        "          \"model\":model,\n",
        "          \"client\":chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
        "          \"embedding_function\":embeddingOpenAICache,\n",
        "          \"custom_text_splitter_function\":splitterCallback,\n",
        "          \"get_or_create\":True,\n",
        "          \"custom_text_types\":autogen.retrieve_utils.TEXT_FORMATS,\n",
        "          \"custom_text_split_function\":splitterCallback.split_text\n",
        "      },\n",
        "      code_execution_config=False\n",
        "  )\n",
        "  return agent"
      ],
      "metadata": {
        "id": "0UuRUTv7amGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module"
      ],
      "metadata": {
        "id": "7ue_7wGgfLU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReturnSummarizeResult(documentList:list,message:str=systemMessage,model:str=\"gemini-pro\")->str:\n",
        "  genai.configure(api_key=userdata.get('GEMINI_API_ADDITIONAL'))\n",
        "  assistant = ReturnAssistantAgent(message)\n",
        "  agent = ReturnProxyAgent(documentList,model)\n",
        "  try:\n",
        "    result = agent.initiate_chat(\n",
        "        assistant,\n",
        "        problem=problem,\n",
        "        clear_history=True\n",
        "    )\n",
        "    if (assistant is not None):\n",
        "      output = RetrieveCallback(assistant)\n",
        "    else:\n",
        "      output = RetrieveCallback(agent)\n",
        "    if (output is not None) and (output != \" \") and (output != \"\"):\n",
        "      if message.lower() == systemMessage.lower():\n",
        "        output = output.strip(\"][\").replace(\"'\",\"\")\n",
        "        output = output.strip('][').replace('\"','').replace(\"]\",\"\").replace(\"[\",\"\").split(', ')\n",
        "      else:\n",
        "        output = output.strip(\"][\").replace(\"'\",\"\")\n",
        "        output = output.strip('][').replace('\"','').replace(\"]\",\"\").replace(\"[\",\"\").split(', ')\n",
        "    else:\n",
        "      output = \"Empty Response\"\n",
        "    assistant.reset()\n",
        "    agent.reset()\n",
        "    return output\n",
        "  except Exception as err:\n",
        "    print(str(err))\n",
        "    try:\n",
        "      assistant.reset()\n",
        "      agent.reset()\n",
        "      return \"Cannot response\"\n",
        "    except Exception as err:\n",
        "      print(str(err))\n",
        "      return \"Cannot response\""
      ],
      "metadata": {
        "id": "dzAMLYqaclJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Personality Creation"
      ],
      "metadata": {
        "id": "SzaUlctKH3Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Related Document Retriever"
      ],
      "metadata": {
        "id": "vjZk-0SuNEtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetRelatedDocuments(searchTarget:str,searchPower:int=1)->list:\n",
        "  if not os.path.exists(\"/content/modelFiles\"):\n",
        "    result,content = WikipediaSearch(str(searchTarget),int(searchPower))\n",
        "    CreatePDFFromURL(result)\n",
        "  contents = SortDirectoryFile(\"/content/modelFiles\")\n",
        "  return contents"
      ],
      "metadata": {
        "id": "uwmD9eqfNGpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure"
      ],
      "metadata": {
        "id": "wZ182wHuH8NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerativePersonality(traits:list,personal:list,name:str,age:int,status:str,llmType:ModelInitial=openAIModel,searchPower:int=5)->ModelInitial:\n",
        "  trait = \", \".join(traits)\n",
        "  memory = GenerativeAgentMemory(\n",
        "      llm=llmType,\n",
        "      memory_retriever=MemoryRetriever(),\n",
        "      verbose=False,\n",
        "      reflection_threshold=8\n",
        "  )\n",
        "  person = GenerativeAgent(\n",
        "      name=str(name),\n",
        "      age=int(age),\n",
        "      traits=trait,\n",
        "      status=str(status),\n",
        "      memory_retriever=MemoryRetriever(),\n",
        "      llm=llmType,\n",
        "      memory=memory\n",
        "  )\n",
        "  for info in personal:\n",
        "    person.memory.add_memory(str(info))\n",
        "  return person"
      ],
      "metadata": {
        "id": "gRCN3kP15TTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response Callback"
      ],
      "metadata": {
        "id": "3UQTgkpdLcwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResponseCallback(message:Optional[str],personType:ModelInitial,nameTarget:str)->str:\n",
        "  response = personType.generate_dialogue_response(str(message))\n",
        "  if len(response) > 0:\n",
        "    if response[0]:\n",
        "      output = response[1]\n",
        "      output = output.replace(f\"{nameTarget} said\",\"\").replace(f\"{nameTarget} said \",\"\")\n",
        "      return output\n",
        "    else:\n",
        "      return ErrorModule().Manuel(ValueError,\"Not Acceptable Process For This Response\")\n",
        "  else:\n",
        "    ErrorModule().Manuel(ValueError,\"Not Acceptable Process For This Response\")\n"
      ],
      "metadata": {
        "id": "pCH1DQ3fQCZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action"
      ],
      "metadata": {
        "id": "jKqCYHgKSHjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ActionPerson(traits:list,personal:list,message:str,nameTarget:str,llmType:ModelInitial=openAIModel,age:int=30,status:str=\"N/A\",searchPower:int=5)->str:\n",
        "  person = GenerativePersonality(\n",
        "      traits,\n",
        "      personal,\n",
        "      name=str(nameTarget),\n",
        "      age=int(age),\n",
        "      status=str(status),\n",
        "      llmType=llmType,\n",
        "      searchPower=int(searchPower)\n",
        "  )\n",
        "  summary = person.get_summary(force_refresh=True)\n",
        "  output = ResponseCallback(message,person,nameTarget=nameTarget)\n",
        "  if output is not None and output != \" \" and output != \" \":\n",
        "    return str(output)\n",
        "  else:\n",
        "    return \"Cannot response for that question\""
      ],
      "metadata": {
        "id": "6Q0xMCl3SJiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch"
      ],
      "metadata": {
        "id": "PtjE3EG4RwVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_Option = \"Nikola Tesla\" # @param [\"Nikola Tesla\", \"Albert Einstein\", \"Madame Curie\"]\n",
        "age_Option = 63 # @param {type:\"slider\", min:20, max:100, step:1}\n",
        "power_Option = 10 # @param {type:\"slider\", min:2, max:10, step:1}\n",
        "status_Option = \"coming back to the life\" # @param [\"coming back to the life\", \"looking for someone to talk to\", \"just wants to chat\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NcjvgvWCRR5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_Option = \"What do you fear most about the future?\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zplbaBEwg_i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'outputTrait' not in globals():\n",
        "  contents = GetRelatedDocuments(person_Option,power_Option)\n",
        "  outputTrait = ReturnSummarizeResult(contents)\n",
        "if 'outputPersonal' not in globals():\n",
        "  contents = GetRelatedDocuments(person_Option,power_Option)\n",
        "  outputPersonal = ReturnSummarizeResult(contents,message=personalMessage)"
      ],
      "metadata": {
        "id": "BOo-sgp2d0Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "output = ActionPerson(\n",
        "    outputTrait,\n",
        "    outputPersonal,\n",
        "    message=str(question_Option),\n",
        "    nameTarget=person_Option,\n",
        "    age=int(age_Option),\n",
        "    searchPower=int(power_Option),\n",
        "    status=str(status_Option)\n",
        ")"
      ],
      "metadata": {
        "id": "k1CByJ1aSGOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_-6G8x47U33X",
        "outputId": "77f9719b-d262-469b-cd20-691e66248596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \"As a forward-thinking individual, my primary concern about the future would be the potential misuse of technology. It is crucial that we use our advancements for the betterment of humanity and not for destructive purposes.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3fagdiLVXq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}