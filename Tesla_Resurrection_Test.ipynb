{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7d8bFExe1hM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install 'pyautogen[gemini]~=0.2.0b4'\n",
        "!pip install 'langchain_experimental==0.0.49'\n",
        "!pip install 'langchain-openai==0.0.3'\n",
        "!pip install 'faiss-cpu==1.7.4'\n",
        "!pip install 'huggingface_hub==0.20.2'\n",
        "!pip install 'wikipedia==1.4.0'\n",
        "!pip install 'google-generativeai==0.3.2'\n",
        "!pip install 'chromadb==0.4.22'\n",
        "!pip install 'pypdf==3.17.4'\n",
        "!pip install 'weasyprint==60.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizations"
      ],
      "metadata": {
        "id": "Ab9JZOewffDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules"
      ],
      "metadata": {
        "id": "piegsyRSfg_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base"
      ],
      "metadata": {
        "id": "jdaHeo3LfjBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union,Optional,List,Dict,Any,Type\n",
        "import faiss,os,shutil,warnings,math"
      ],
      "metadata": {
        "id": "MDmT2WYYfX-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generative Related"
      ],
      "metadata": {
        "id": "5Ho6l5bZf7Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai,autogen\n",
        "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "import google.generativeai as genai\n",
        "from langchain_experimental.generative_agents import GenerativeAgent,GenerativeAgentMemory\n",
        "from langchain_openai import OpenAI as LOpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "RM_GJ0wrf-OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain Related"
      ],
      "metadata": {
        "id": "b686uwxtgoZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "H9Mx6G1hgn1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Related"
      ],
      "metadata": {
        "id": "4cCWm-yjhbtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import chromadb,faiss\n",
        "from chromadb.utils import embedding_functions"
      ],
      "metadata": {
        "id": "4zSdfmNYhX1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Related"
      ],
      "metadata": {
        "id": "FUCDv_RniC3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata,drive"
      ],
      "metadata": {
        "id": "HGG6vvZ8h_8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Related"
      ],
      "metadata": {
        "id": "li_7Ou3DvTAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weasyprint\n",
        "import wikipedia as wpp\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
        "from autogen.code_utils import content_str"
      ],
      "metadata": {
        "id": "g4lin67FvUga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "hQmYVxJZiLgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
      ],
      "metadata": {
        "id": "iLj0S-WTiKRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class"
      ],
      "metadata": {
        "id": "huOe5EE3icBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassInitial:\n",
        "  pass\n",
        "class ProcessInitial:\n",
        "  pass\n",
        "class FunctionInitial:\n",
        "  pass\n",
        "class NullInitial:\n",
        "  pass\n",
        "class DocumentationInitial:\n",
        "  pass\n",
        "class ErrorInitial:\n",
        "  pass\n",
        "class ModelInitial:\n",
        "  pass"
      ],
      "metadata": {
        "id": "2NoWJiwbiZVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "i5PY0NMair4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "createDirectory:FunctionInitial = lambda x: os.mkdir(x) if not os.path.exists(x) else None\n",
        "deleteDirectory:FunctionInitial = lambda x: shutil.rmtree(x) if len(os.listdir(x)) > 1 else None\n",
        "sortDirectory:FunctionInitial = lambda x: [str(x)+str(y) for y in os.listdir(str(x)) if y != \".ipynb_checkpoints\"]\n",
        "relevanceScore:FunctionInitial = lambda x: 1.0-x/math.sqrt(2)"
      ],
      "metadata": {
        "id": "MGvxGmWiiqkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def StringToList(output:str)->list:\n",
        "  output = output.strip(\"][\").replace(\"'\",\"\")\n",
        "  output = output.strip('][').replace('\"','').replace(\"]\",\"\").replace(\"[\",\"\").split(\", \")\n",
        "  return output"
      ],
      "metadata": {
        "id": "-C0V85GKaVNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ErrorModule(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.error:ErrorInitial = NotImplementedError(NotImplemented)\n",
        "  def __str__(self)->str:\n",
        "    return \"Error Modulation\"\n",
        "  def __call__(self)->ErrorInitial:\n",
        "    return self.error\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    raise self.error\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return ErrorModule.__doc__\n",
        "  @property\n",
        "  def Default(self)->ErrorInitial:\n",
        "    raise self.error\n",
        "  def Manuel(self,errorType:ErrorInitial,errorMessage:str)->ErrorInitial:\n",
        "    raise errorType(errorMessage)"
      ],
      "metadata": {
        "id": "gwfOROgjjKaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DefineCredentials(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.openAIKey = userdata.get(\"OPENAI_API_KEY\")\n",
        "    self.huggingKey = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "    self.googleKey = userdata.get(\"GOOGLE_API_ADDITIONAL\")\n",
        "    self.geminiKey = userdata.get(\"GEMINI_API_ADDITIONAL\")\n",
        "    self.cseIDKey = userdata.get(\"CSE_ID_KEY\")\n",
        "  def __str__(self)->str:\n",
        "    return \"Credentials Modulation\"\n",
        "  def __call__(self)->NullInitial:\n",
        "    return None\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    ErrorModule().Default\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return DefineCredentials.__doc__\n",
        "  def SaveOpenAI(self)->ProcessInitial:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = self.openAIKey\n",
        "    openai.api_key = self.openAIKey\n",
        "    print(\"+ OPENAI API KEY - [HAS BEEN SAVED]\")\n",
        "  def SaveGemini(self)->ProcessInitial:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = self.geminiKey\n",
        "    print(\"+ GEMINI API KEY - [HAS BEEN SAVED]\")\n",
        "  def SaveGoogle(self)->ProcessInitial:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = self.googleKey\n",
        "    os.environ[\"GOOGLE_CSE_ID\"] = self.cseIDKey\n",
        "    print(\"+ GOOGLE & CSE API KEY - [HAS BEEN SAVED]\")\n",
        "  def SaveHugging(self)->ProcessInitial:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = self.huggingKey\n",
        "    globals()[\"HUGGING_KEY\"] = self.huggingKey\n",
        "    !huggingface-cli login --token $HUGGING_KEY\n",
        "    print(\"+ HUGGING API KEY - [HAS BEEN SAVED]\")"
      ],
      "metadata": {
        "id": "InQFDgoKjtJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "KUdmJ_39k9Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().SaveOpenAI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psngpcK-k5ln",
        "outputId": "b1b2bc84-2431-4e43-e5da-4647b3d21420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ OPENAI API KEY - [HAS BEEN SAVED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().SaveGemini()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWE31jtLlL9Z",
        "outputId": "30fa52c7-4475-4c71-e757-dce12f8ca210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ GEMINI API KEY - [HAS BEEN SAVED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().SaveGoogle()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLWvqBb5lQoV",
        "outputId": "5456893c-ae7e-4e18-f66a-07e731dea3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ GOOGLE & CSE API KEY - [HAS BEEN SAVED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DefineCredentials().SaveHugging()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wKruCHXlSf-",
        "outputId": "ad543a38-e795-46c9-df07-e3b7e2ce3afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "+ HUGGING API KEY - [HAS BEEN SAVED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autogenConfiguration:list = [\n",
        "    {\n",
        "        \"model\":\"gpt-4-1106-preview\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\":\"gpt-4-vision-preview\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\":\"dalle\",\n",
        "        \"api_key\":os.environ.get(\"OPENAI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gemini-pro\",\n",
        "        \"api_key\": os.environ.get(\"GEMINI_API_KEY\")\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gemini-pro-vision\",\n",
        "        \"api_key\": os.environ.get(\"GEMINI_API_KEY\")\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "YtyFrf4rlnbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Modulation"
      ],
      "metadata": {
        "id": "VjWaoRv6lxmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure"
      ],
      "metadata": {
        "id": "6mrKCrSLuxLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMStructure(object):\n",
        "  def __init__(self)->ClassInitial:\n",
        "    self.mistral = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "    self.modelOpenAI = \"gpt-4\"\n",
        "  def __str__(self)->str:\n",
        "    return \"LLM Structure Modulation\"\n",
        "  def __call__(self)->NullInitial:\n",
        "    return None\n",
        "  def __getstate__(self)->ErrorInitial:\n",
        "    ErrorModule().Default\n",
        "  def __repr__(self)->DocumentationInitial:\n",
        "    return LLMStructure.__doc__\n",
        "  def Load(self,LLMType:str=\"openai\")->ModelInitial:\n",
        "    if LLMType.lower() == \"openai\":\n",
        "      llm = ChatOpenAI(\n",
        "          temperature=0.3,\n",
        "          max_tokens=4096,\n",
        "          model_name=self.modelOpenAI,\n",
        "          presence_penalty=2.0,\n",
        "          frequency_penalty=1.0,\n",
        "          timeout=300\n",
        "      )\n",
        "    elif LLMType.lower() == \"hugging\":\n",
        "      llm = HuggingFaceHub(\n",
        "          repo_id=self.mistral,\n",
        "          task=\"conversational\",\n",
        "          model_kwargs={\n",
        "              \"temperature\":0.2,\n",
        "              \"repetition_penalty\":1.03,\n",
        "              \"max_new_tokens\":512\n",
        "          }\n",
        "      )\n",
        "    else:\n",
        "      ErrorModule().Manuel(ValueError,\"[LLM Type is not valid]\")\n",
        "    return llm"
      ],
      "metadata": {
        "id": "7bQQyk1dlsQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "qiAhT26ruzvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openAIModel = LLMStructure().Load(\"openai\")\n",
        "mistralModel = LLMStructure().Load(\"hugging\")"
      ],
      "metadata": {
        "id": "FtSpbFP4uvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gathering Operations"
      ],
      "metadata": {
        "id": "KPCIay4HvAlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wikipedia"
      ],
      "metadata": {
        "id": "SruAE5LrwESR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WikipediaSearch(topic:Optional[str],limit:Optional[int],**load_kwargs:Any)->list|tuple:\n",
        "  urls = []\n",
        "  contents = []\n",
        "  response = wpp.search(\n",
        "      topic,\n",
        "      results=limit\n",
        "  )\n",
        "  if (len(response) > 0) and (response is not None):\n",
        "    for index in response:\n",
        "      try:\n",
        "        url = wpp.page(\n",
        "            str(index),\n",
        "            **load_kwargs\n",
        "        ).url\n",
        "        urls.append(url)\n",
        "      except:\n",
        "        pass\n",
        "      try:\n",
        "        content = wpp.page(\n",
        "            str(index),\n",
        "            **load_kwargs\n",
        "        ).content\n",
        "        contents.append(content)\n",
        "      except:\n",
        "        pass\n",
        "    return urls,contents\n",
        "  else:\n",
        "    return [],[]"
      ],
      "metadata": {
        "id": "PriDgxMfu85L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Search"
      ],
      "metadata": {
        "id": "w4xtpBeIxZjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GoogleSearch(query:Optional[str],limit:Optional[int]=10)->list:\n",
        "  defaultQuery = f\"Life and personality of {str(query)}\"\n",
        "  wrapper = GoogleSearchAPIWrapper(k=1,siterestrict=False)\n",
        "  result = wrapper.results(query=defaultQuery,num_results=int(limit))\n",
        "  urls = []\n",
        "  if (len(result) > 0) and (result is not None):\n",
        "    for rs in result:\n",
        "      url = rs[\"link\"]\n",
        "      urls.append(url)\n",
        "    return urls\n",
        "  else:\n",
        "    return []"
      ],
      "metadata": {
        "id": "KNHilYcXxbOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF Creating"
      ],
      "metadata": {
        "id": "drKgt9clwFom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CreatePDF(urls:List)->ProcessInitial:\n",
        "  createDirectory(os.path.join(os.getcwd(),\"target_files\"))\n",
        "  if len(urls) > 0:\n",
        "    for idx,url in enumerate(urls):\n",
        "      try:\n",
        "        engine = weasyprint.HTML(url).write_pdf()\n",
        "        path = os.path.join(os.path.join(os.getcwd(),\"target_files\"),f\"target_doc_{str(idx)}.pdf\")\n",
        "        with open(path,\"wb\") as ops:\n",
        "          ops.write(engine)\n",
        "      except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "yeWDILZXwDUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Structure"
      ],
      "metadata": {
        "id": "seSjSzM3yzfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Design"
      ],
      "metadata": {
        "id": "Cv03y2Md1QIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddingModel:ModelInitial = OpenAIEmbeddings(\n",
        "      model=\"text-embedding-ada-002\",\n",
        "      embedding_ctx_length=8191,\n",
        "      api_key=userdata.get(\"OPENAI_API_KEY\"),\n",
        "      chunk_size=1000,\n",
        "      max_retries=2,\n",
        "      timeout=300\n",
        "  )"
      ],
      "metadata": {
        "id": "IOdhDNPZ1P3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure"
      ],
      "metadata": {
        "id": "NeIPVKExzWOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MemoryRetriever()->ModelInitial:\n",
        "  indexFlat = faiss.IndexFlatL2(1536)\n",
        "  store = FAISS(\n",
        "      embeddingModel.embed_query,\n",
        "      indexFlat,\n",
        "      InMemoryDocstore({}),\n",
        "      {},\n",
        "      relevance_score_fn=relevanceScore\n",
        "  )\n",
        "  vector = TimeWeightedVectorStoreRetriever(\n",
        "      vectorstore=store,\n",
        "      other_score_keys=[\"importance\"],\n",
        "      k=5,\n",
        "      decay_rate=0.0000001\n",
        "  )\n",
        "  return vector"
      ],
      "metadata": {
        "id": "52dStP5HzT-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing Model"
      ],
      "metadata": {
        "id": "sfg1zcq00wrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Design"
      ],
      "metadata": {
        "id": "NNfkeQZszFuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddingModelCache:FunctionInitial = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=userdata.get(\"OPENAI_API_KEY\"),\n",
        "    model_name=\"text-embedding-ada-002\"\n",
        ")"
      ],
      "metadata": {
        "id": "n7lcjMLkxJ5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "-VrdSKvs01eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "systemCommand = (\n",
        "    \"Extract personality traits in detail from the documents given to you, and identify at least 10 personality traits. \"\n",
        "    \"Determine these personal characteristics objectively and clearly. \"\n",
        "    \"Extract all the traits of personality according to the documents you have.\"\n",
        ")\n",
        "autoReply = \"Always give the final answer as text and add 'TERMINATE' at the end\"\n",
        "problem = (\n",
        "    \"Using these documents, extract personality traits and return them as a string array. \"\n",
        "    \"Export this as a list.\"\n",
        ")"
      ],
      "metadata": {
        "id": "_XJgPPdJ0k15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitter Design"
      ],
      "metadata": {
        "id": "eK7a6lnx1WAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "separators = [\n",
        "    \"\\n#{1,6} \",\n",
        "    \"```\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "    \"\\r\",\n",
        "    \"\\t\"\n",
        "]"
      ],
      "metadata": {
        "id": "YZPWfQUZ1FuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    strip_whitespace=True,\n",
        "    separators=separators\n",
        ")"
      ],
      "metadata": {
        "id": "Ro9dUhrC14fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assistant"
      ],
      "metadata": {
        "id": "IfO-Rso82QEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetSummarizingAssistant(message:str=systemCommand)->ModelInitial:\n",
        "  assistant = RetrieveAssistantAgent(\n",
        "      name=\"personality_traits_assistant\",\n",
        "      system_message=message,\n",
        "      llm_config={\n",
        "          \"timeout\":300,\n",
        "          \"cache_seed\":42,\n",
        "          \"config_list\":autogenConfiguration\n",
        "      }\n",
        "  )\n",
        "  return assistant"
      ],
      "metadata": {
        "id": "uUop_7Bt2KyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proxy"
      ],
      "metadata": {
        "id": "gtYbQRWZ2q4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetSummarizingProxy(targetDocuments:List,modelType:str=\"gemini-pro\")->ModelInitial:\n",
        "  createDirectory(os.path.join(os.getcwd(),\"target_files\"))\n",
        "  targetPath = os.path.join(os.path.abspath(\"\"),\"target_files\")\n",
        "  targetDocuments.append(targetPath)\n",
        "  proxy = RetrieveUserProxyAgent(\n",
        "      name=\"ragproxyagent\",\n",
        "      human_input_mode=\"NEVER\",\n",
        "      default_auto_reply=autoReply,\n",
        "      max_consecutive_auto_reply=20,\n",
        "      retrieve_config={\n",
        "          \"task\":\"qa\",\n",
        "          \"docs_path\":targetDocuments,\n",
        "          \"chunk_token_size\":2000,\n",
        "          \"model\":str(modelType),\n",
        "          \"client\":chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
        "          \"embedding_function\":embeddingModelCache,\n",
        "          \"custom_text_splitter_function\":splitter,\n",
        "          \"get_or_create\":True,\n",
        "          \"custom_text_types\":autogen.retrieve_utils.TEXT_FORMATS,\n",
        "          \"custom_text_split_function\":splitter.split_text\n",
        "      },\n",
        "      code_execution_config=False\n",
        "  )\n",
        "  return proxy"
      ],
      "metadata": {
        "id": "rB7Zl2VK2pki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response Callback"
      ],
      "metadata": {
        "id": "jCpz03XCbcC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReturnCallback(retModel:ModelInitial,problem:str=problem,description:str=autoReply)->str:\n",
        "  for value in retModel.chat_messages.values():\n",
        "    if (value) and (len(value) > 0):\n",
        "      for idx in value:\n",
        "        if (idx[\"content\"] is not None) and (idx[\"content\"] != \" \") and (idx[\"content\"].lower() != str(problem).lower()) and (idx[\"content\"].lower() != str(description).lower()) and (idx[\"content\"] != \"\") and (idx[\"content\"].upper() != \"UPDATE CONTEXT\"):\n",
        "          try:\n",
        "            content = content_str(idx[\"content\"])\n",
        "          except:\n",
        "            content = idx[\"content\"]\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      content = None\n",
        "  return content"
      ],
      "metadata": {
        "id": "RL839g3Vbeyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modulation"
      ],
      "metadata": {
        "id": "1MQLSsHS2qTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetSummarizingResult(documentList:list,message:str=systemCommand,modelType:str=\"gemini-pro\",problem:str=problem)->str:\n",
        "  genai.configure(api_key=userdata.get(\"GEMINI_API_ADDITIONAL\"))\n",
        "  assistant = GetSummarizingAssistant(message)\n",
        "  proxy = GetSummarizingProxy(documentList,modelType)\n",
        "  try:\n",
        "    result = proxy.initiate_chat(\n",
        "        assistant,\n",
        "        problem=problem,\n",
        "        clear_history=True\n",
        "    )\n",
        "    if (assistant is not None):\n",
        "      output = ReturnCallback(assistant)\n",
        "    else:\n",
        "      output = ReturnCallback(proxy)\n",
        "    if output is not None:\n",
        "      output = StringToList(output)\n",
        "    else:\n",
        "      output = \"[The model got complicated while responding]\"\n",
        "    try:\n",
        "      assistant.reset()\n",
        "      proxy.reset()\n",
        "    except Exception as err:\n",
        "      print(err)\n",
        "      pass\n",
        "    return output\n",
        "  except Exception as err:\n",
        "    print(err)\n",
        "    try:\n",
        "      assistant.reset()\n",
        "      proxy.reset()\n",
        "      return \"[The model got complicated while responding]\"\n",
        "    except Exception as err:\n",
        "      print(err)\n",
        "      return \"[The model got complicated while responding]\""
      ],
      "metadata": {
        "id": "XxbsLPhCaxd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resurrection"
      ],
      "metadata": {
        "id": "ste5nj1RdPFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gathering Related Informations"
      ],
      "metadata": {
        "id": "fTJIgyPBdQw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetInformation(target:Optional[str],limit:int=10)->list:\n",
        "  if not os.path.exists(os.path.join(os.getcwd(),\"target_files\")):\n",
        "    urls,contents = WikipediaSearch(str(target),int(limit))\n",
        "    googleURLS = GoogleSearch(str(target),int(limit))\n",
        "    urls.extend(googleURLS)\n",
        "    if len(urls) > 0:\n",
        "      CreatePDF(urls)\n",
        "    else:\n",
        "      ErrorModule().Manuel(ValueError,\"[No linked data records found]\")\n",
        "  path = os.path.join(os.getcwd(),\"target_files\")\n",
        "  path = path + \"/\" if not path.endswith(\"/\") else path\n",
        "  files = sortDirectory(path)\n",
        "  return files"
      ],
      "metadata": {
        "id": "u6mmkfIAdJsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback"
      ],
      "metadata": {
        "id": "_HvXwMM-g4V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PersonReturnCallback(message:Optional[str],person:ModelInitial,nameTarget:str)->str:\n",
        "  response = person.generate_dialogue_response(str(message))\n",
        "  reaction = person.generate_reaction(str(message))\n",
        "  if (len(response) > 0) and (response is not None):\n",
        "    if response[0]:\n",
        "      output = response[1]\n",
        "      output = output.replace(f\"{nameTarget} said\",\"\").replace(f\"{nameTarget} said \",\"\")\n",
        "      return output,reaction\n",
        "    else:\n",
        "      ErrorModule().Manuel(ValueError,\"[Not acceptable process for this response]\")\n",
        "  else:\n",
        "    ErrorModule().Manuel(ValueError,\"[Not acceptable process for this response]\")"
      ],
      "metadata": {
        "id": "Fv2V0h1cg5bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modulation"
      ],
      "metadata": {
        "id": "-i9ulwJWfSpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerativePersonality(traits:list,personal:list,dailyActivities:list,name:str,age:int,status:str,llmType:ModelInitial=openAIModel,limit:int=5)->ModelInitial:\n",
        "  traits = \", \".join(traits)\n",
        "  memory = GenerativeAgentMemory(\n",
        "      llm=llmType,\n",
        "      memory_retriever=MemoryRetriever(),\n",
        "      verbose=False,\n",
        "      reflection_threshold=8,\n",
        "      max_tokens_limit=1200,\n",
        "      importance_weight=0.15\n",
        "  )\n",
        "  if dailyActivities != \"[The model got complicated while responding]\":\n",
        "    person = GenerativeAgent(\n",
        "        name=str(name),\n",
        "        age=int(age),\n",
        "        traits=traits,\n",
        "        status=str(status),\n",
        "        memory_retriever=MemoryRetriever(),\n",
        "        llm=llmType,\n",
        "        memory=memory,\n",
        "        summary_refresh_seconds=3600,\n",
        "        daily_summaries=dailyActivities\n",
        "    )\n",
        "  else:\n",
        "      person = GenerativeAgent(\n",
        "        name=str(name),\n",
        "        age=int(age),\n",
        "        traits=traits,\n",
        "        status=str(status),\n",
        "        memory_retriever=MemoryRetriever(),\n",
        "        llm=llmType,\n",
        "        memory=memory,\n",
        "        summary_refresh_seconds=3600\n",
        "    )\n",
        "  if personal != \"[The model got complicated while responding]\":\n",
        "    for info in personal:\n",
        "      person.memory.add_memory(str(info))\n",
        "  return person"
      ],
      "metadata": {
        "id": "WF5dDKbwfM5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action"
      ],
      "metadata": {
        "id": "HtIGNuUHhiIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LaunchPerson(message:str,traits:list,personal:list,dailyActivities:list,name:str,age:int,status:str=\"N/A\",llmType:ModelInitial=openAIModel,limit:int=5)->str:\n",
        "  person = GenerativePersonality(\n",
        "      traits,\n",
        "      personal,\n",
        "      dailyActivities=dailyActivities,\n",
        "      name=name,\n",
        "      age=age,\n",
        "      status=status,\n",
        "      llmType=llmType,\n",
        "      limit=limit\n",
        "  )\n",
        "  summary = person.get_summary(force_refresh=True)\n",
        "  output,reaction = PersonReturnCallback(message,person,nameTarget=name)\n",
        "  return str(output),summary,reaction"
      ],
      "metadata": {
        "id": "ILqx5LEkgtp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch"
      ],
      "metadata": {
        "id": "n549n8zwikyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "Nh1N8l2IimNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetPerson = \"Nikola Tesla\"\n",
        "targetAge = 30\n",
        "targetLimit = 5\n",
        "targetStatus = \"coming back to life\""
      ],
      "metadata": {
        "id": "7_Dr9jo1if59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gathering Personality"
      ],
      "metadata": {
        "id": "11axJ_uIizg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personalMessage = (\n",
        "    \"Use one-sentence descriptive phrases. \"\n",
        "    \"Make complete sentences in accordance with the language rules. \"\n",
        "    \"For example: 'He/she remembers his/her dog, from when he/she was a kid', 'He/she feels tired from driving so far', 'He/she sees the new home'. \"\n",
        "    \"Return them as a string array. \"\n",
        "    \"Array must consist of at least 10 items.\"\n",
        ")\n",
        "personalProblem = (\n",
        "    \"Provide self-information about personality in accordance with the documents given to you. \"\n",
        "    \"Use one-sentence descriptive phrases. \"\n",
        "    \"For example: 'He/she remembers his/her dog, from when he/she was a kid', 'He/she feels tired from driving so far', 'He/she sees the new home'. \"\n",
        "    \"Return them as a string array. \"\n",
        ")"
      ],
      "metadata": {
        "id": "WLgTyP1WjceG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaryMessage = (\n",
        "    \"Using the documents uploaded to you as a reference, present the 10-day activities as an array list. \"\n",
        "    \"These daily activities must be in line with reality and the documents given to you. \"\n",
        "    \"Use one-sentence descriptive phrases. \"\n",
        "    \"Return them as a string array.\"\n",
        ")\n",
        "summaryProblem = (\n",
        "    \"Using the documents uploaded to you as a reference, present the 10-day activities as an array list. \"\n",
        "    \"Return them as a string array.\"\n",
        ")"
      ],
      "metadata": {
        "id": "qOkkvJq3xCtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = GetInformation(targetPerson,targetLimit)"
      ],
      "metadata": {
        "id": "nx_PQYPzj2sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traits = GetSummarizingResult(files)"
      ],
      "metadata": {
        "id": "Uccin0YJizDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#personal = GetSummarizingResult(files,personalMessage,problem=personalProblem)"
      ],
      "metadata": {
        "id": "oNldJb14qv4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dailySummaries = GetSummarizingResult(files,summaryMessage,problem=summaryProblem)"
      ],
      "metadata": {
        "id": "OhmYxtHBw__u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personal = [\n",
        "    \"Nikola Tesla was a brilliant inventor, known for his pioneering contributions to the development of alternating current (AC) electrical systems.\",\n",
        "    \"Tesla was a polyglot, fluent in several languages including English, French, German, and his native Serbo-Croatian.\",\n",
        "    \"Despite his numerous inventions and contributions to science, Tesla often struggled financially and lived much of his life in relative poverty.\",\n",
        "    \"He was a bachelor throughout his life, never marrying or having children, and was known to have said he felt he could not be as dedicated to his work if he were to marry.\",\n",
        "    \"He was known for his eccentric personality, including an intense fear of germs and obsessive-compulsive behaviors such as requiring a stack of 18 napkins at every meal.\",\n",
        "    \"Tesla had a strong ethical principle against war and violence, and he hoped that his inventions would contribute to peace on Earth.\",\n",
        "    \"Despite his achievements, he received relatively little recognition during his lifetime and died alone in a New York hotel room in 1943.\"\n",
        "]"
      ],
      "metadata": {
        "id": "3rDUPHlH2Iv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dailySummaries = [\n",
        "    \"Nikola Tesla begins his day with a morning walk, often contemplating new inventions and theories as he enjoys the solitude of dawn.\",\n",
        "    \"After his walk, Tesla spends time feeding and caring for his beloved pigeons, with whom he shares a unique bond.\",\n",
        "    \"Tesla takes a brief midday break to dine alone, preferring simple meals that support his rigorous mental and physical discipline.\",\n",
        "    \"In the late afternoon, he goes for another walk, using this time to mentally solve complex problems and conceive new ideas.\",\n",
        "    \"He spends some time each day working on his physical health, engaging in exercises that promote his well-being and support his capacity for intense mental focus.\",\n",
        "    \"Before retiring for the night, Tesla often reads a wide range of topics, from poetry to scientific treatises, fueling both his imagination and intellectual curiosity.\"\n",
        "]"
      ],
      "metadata": {
        "id": "7nTcviE1x6sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h66BH-2ojSWe",
        "outputId": "786c6272-33f9-4745-8740-51b0a849002b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visionary',\n",
              " 'multilingual',\n",
              " 'workaholic',\n",
              " 'eccentric',\n",
              " 'obsessive',\n",
              " 'compulsive',\n",
              " 'innovative',\n",
              " 'solitary',\n",
              " 'meticulous',\n",
              " 'frugal']"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "MCUtJ1PnsnMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What do you think about wars?\""
      ],
      "metadata": {
        "id": "dufIzq6J3cvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "response,summary,reaction = LaunchPerson(\n",
        "    message=question,\n",
        "    traits=traits,\n",
        "    personal=personal,\n",
        "    dailyActivities=dailySummaries,\n",
        "    name=targetPerson,\n",
        "    age=targetAge,\n",
        "    status=targetStatus,\n",
        "    limit=targetLimit\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqpbmBt7lEGQ",
        "outputId": "60262aeb-6266-4700-80cf-77c73c684c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQPjJ40RlqIE",
        "outputId": "206f0e60-a736-46a0-cdb6-c290271a7056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"I have always been a staunch advocate for peace. Wars are destructive and cause immense suffering, not just to the people directly involved but also to humanity as a whole. They hinder progress and divert resources that could be used for the betterment of mankind towards destruction instead. I believe in using science and technology for peaceful purposes, with an aim to improve lives rather than destroy them.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCMCZ88EmSZG",
        "outputId": "97b5de3c-d28c-4d41-c1e6-0fb217806252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Nikola Tesla (age: 30)\n",
            "Innate traits: visionary, multilingual, workaholic, eccentric, obsessive, compulsive, innovative, solitary, meticulous, frugal\n",
            "Nikola Tesla was a brilliant and ethical inventor, known for his significant contributions to the development of AC electrical systems. Despite his inventions, he struggled financially and received little recognition during his lifetime. He lived in relative poverty and died alone in 1943. Fluent in several languages including English, French, German, and Serbo-Croatian; Tesla had strong principles against war and violence hoping that his work would contribute to global peace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reaction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcC9ckdGsgzu",
        "outputId": "664d43be-76de-4cd0-f51e-7b70a5e7c43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(True, 'Nikola Tesla said \"As I mentioned earlier, my mother was a remarkable woman with an inventive spirit and mechanical abilities. She could craft household appliances from virtually nothing which greatly inspired me. Her memory for Serbian epic poems was also extraordinary.\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtQ7rBWg3X-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}